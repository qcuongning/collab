{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thyroid_nod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcuongning/collab/blob/main/Thyroid_nodule_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhF704nMmIx"
      },
      "source": [
        "Với các hàm cần sử dụng backend Keras mà bị lỗi K not contribute cần đổi về keras==2.2.4\n",
        "\n",
        "\n",
        "The codebase is heavily inspired by the [respotory](https://github.com/qubvel/efficientnet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80XmdWXlUgZG"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnbEu1yz0PKx"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications as app\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "from zipfile import ZipFile\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEODECWeDwKL",
        "outputId": "c5099bc7-b123-44f6-862f-33d1a0b40df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-209d2e5a43b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BmpPr1ID0Mz"
      },
      "source": [
        "file_id = '1bbKAqUuk7Y1q3xsDSwP07oOXN_GL3SQM'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('COVID-SemiSegz')\n",
        "with ZipFile('COVID-SemiSegz', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9wexv7y7QeG",
        "outputId": "3d51f130-713d-44ad-df80-36e29389dc91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc20AZFtGeyk"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/COVID-SemiSeg.zip /content/\n",
        "with ZipFile('COVID-SemiSeg.zip', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOs9YUGVujtH"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/thyroid.zip /content/\n",
        "with ZipFile('thyroid.zip', 'r') as tt:\n",
        "  tt.extractall(\"thyroid\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNhqAQK442Z"
      },
      "source": [
        "file_name = 'weights_save'\n",
        "if not os.path.exists(file_name):\n",
        "  os.mkdir(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDGT7k5XUtJY"
      },
      "source": [
        "# Initial Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS-_PJSBTLfr"
      },
      "source": [
        "lấy các cặp ảnh và mask\n",
        "\n",
        "ảnh resize về 192x288\n",
        "\n",
        "mask là binary\n",
        "đầu ra imgs , masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDRtMZfNvfJn"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "ff = os.listdir(\"thyroid\")\n",
        "images = []\n",
        "masks = []\n",
        "for count,f in enumerate(ff):\n",
        "    if f.find(\".jpg\")>0:\n",
        "        img = cv2.imread(\"thyroid/\"+f,0)\n",
        "        mask = np.zeros_like(img)\n",
        "        ix_number = f.find(\"_\")\n",
        "        rep = f[ix_number+1:ix_number+2]\n",
        "        if ix_number < 0:\n",
        "            ix_number = f.find(\".\")\n",
        "        number = f[:ix_number]\n",
        "        if number==\"127\" or number=='54' or number=='165' or number=='176' or number=='203' or number=='205' or number=='166' or number=='197':\n",
        "            continue\n",
        "        #print(number)\n",
        "        root = ET.parse(\"thyroid/\"+number+\".xml\").getroot()\n",
        "        #print(\"so anh: \",len(root.findall(\"mark\")))\n",
        "        for neighbor in root.findall(\"mark\"):\n",
        "            if rep !=  neighbor.find(\"image\").text:\n",
        "                continue\n",
        "            svg = neighbor.find(\"svg\").text\n",
        "            if svg is None:\n",
        "                continue\n",
        "            ss = eval(svg)\n",
        "            for s in ss:\n",
        "                contour = []\n",
        "                for point in s[\"points\"]:\n",
        "                    x = point[\"x\"]\n",
        "                    y = point['y']\n",
        "                    contour.append([[x,y]])\n",
        "                contour = np.asarray(contour)\n",
        "                cv2.drawContours(mask, [contour], 0, 255, -1)\n",
        "            mask = mask/255\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "        if count%100 == 0:\n",
        "            print(f)\n",
        "            plt.figure(count//50,figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
        "            plt.subplot(1,3,1).imshow(img,cmap='gray')\n",
        "            plt.subplot(1,3,2).imshow(img,cmap='gray')\n",
        "            plt.contour(mask, [0], colors='r')\n",
        "            plt.subplot(1,3,3).imshow(mask, cmap = 'gray')\n",
        "            plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFXg1utzw1e9"
      },
      "source": [
        "def GetFiles(path):\n",
        "    file_list, dir_list = [], []\n",
        "    for dir, subdirs, files in os.walk(path):\n",
        "        file_list.extend([FJoin(dir, f) for f in files])\n",
        "        dir_list.extend([FJoin(dir, d) for d in subdirs])\n",
        "    return file_list, dir_list\n",
        "\n",
        "def get_mask(image_name,mask_folder):\n",
        "    mask_path=os.path.join(mask_folder, image_name.replace(\".jpg\",\".png\"))\n",
        "    #print(mask_path)\n",
        "    img_mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
        "    _,img_mask = cv2.threshold(img_mask,127,255,cv2.THRESH_BINARY)\n",
        "    #img_mask = img_mask/255\n",
        "    #plt.imshow(img_mask,cmap='gray')\n",
        "    img_mask[img_mask<0.5] = 0\n",
        "    img_mask[img_mask>=0.5] = 1\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def build_data(path,mask_folder,edge_folder, csv_path,img_shapes):\n",
        "  w,h = img_shapes\n",
        "  imgs=[]\n",
        "  masks=[]\n",
        "  edges = []\n",
        "  img_name=[]\n",
        "  if csv_path == None:\n",
        "    img_name = os.listdir(path)\n",
        "  else:\n",
        "    with open(csv_path, 'r') as csvFile:\n",
        "      reader = csv.reader(csvFile)\n",
        "      for row in reader:\n",
        "          img_name.append(row[0])\n",
        "  n = len(img_name)//20\n",
        "  for count,file in enumerate(img_name[:]):\n",
        "        if file.find(\"super\")>0:\n",
        "          continue\n",
        "        fullpath= os.path.join(path,file)\n",
        "        #print(fullpath)\n",
        "        msk=get_mask(file,mask_folder)\n",
        "        if edge_folder is not None:\n",
        "          edge = get_mask(file,edge_folder)\n",
        "          edge=cv2.resize(edge,(w,h))\n",
        "          edges.append(edge)\n",
        "        msk=cv2.resize(msk,(w,h))\n",
        "        masks.append(msk)\n",
        "        image=cv2.imread(fullpath)\n",
        "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        #image=image/127.5-1\n",
        "        image=cv2.resize(image,(w,h))\n",
        "        imgs.append(image)\n",
        "        if count%n == 0:\n",
        "          plt.figure(count//n)\n",
        "          plt.subplot(1,2,1).imshow(image,cmap='gray')\n",
        "          #plt.contour(msk,colors='r')\n",
        "          #plt.draw()\n",
        "          plt.subplot(1,2,2).imshow(msk, cmap = 'gray')\n",
        "          plt.show()  \n",
        "  imgs=np.asarray(imgs,dtype=np.float)\n",
        "  masks=np.asarray(masks,dtype=np.float).reshape(-1,h,w,1)\n",
        "  edges=np.asarray(edges,dtype=np.float).reshape(-1,h,w,1)\n",
        "  print(\"shape imgs: \",imgs.shape)\n",
        "  print(\"shape masks: \",masks.shape)\n",
        "  return imgs,masks,edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJXIQ68RY5e"
      },
      "source": [
        "w = 352\n",
        "h = 352\n",
        "#folder_train = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Doctor-label/Imgs\"\n",
        "folder_train = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Doctor-label/Imgs\"  # thay folder Doctor -> Pseudo để lấy 1600 ảnh pseudo train\n",
        "mask_train_folder = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Doctor-label/GT\"\n",
        "edge_train_folder = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Doctor-label/Edge\"\n",
        "\n",
        "#mask_train_folder = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Pseudo-label/GT\"\n",
        "folder_test = \"/content/COVID-SemiSeg/Dataset/TestingSet/LungInfection-Test/Imgs\"\n",
        "mask_test_folder = \"/content/COVID-SemiSeg/Dataset/TestingSet/LungInfection-Test/GT\"\n",
        "edge_dev_folder = None\n",
        "imgs,masks,edge = build_data(folder_train,mask_train_folder,edge_train_folder, None, (w,h))\n",
        "print(\"---------------------------------------------------------\")\n",
        "img_dev,mask_dev,edge_dev = build_data(folder_test,mask_test_folder,edge_dev_folder, None, (w,h))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u0pxsIm6BIe"
      },
      "source": [
        "#loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GFsmYJUVfUO"
      },
      "source": [
        "def mvn(tensor):\n",
        "    '''Performs per-channel spatial mean-variance normalization.'''\n",
        "    epsilon = 1e-6\n",
        "    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n",
        "    std = K.std(tensor, axis=(1,2), keepdims=True)\n",
        "    mvn = (tensor - mean) / (std + epsilon)\n",
        "    \n",
        "    return mvn\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    '''Average dice coefficient per batch.'''\n",
        "    y_pred = heviside(y_pred,epsilon = 0.01)\n",
        "    axes = (1,2,3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes) #AhopM\n",
        "    summation = K.sum(y_true + y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred, smooth=1.0)\n",
        "def gradientLoss2d(input):\n",
        "    dH = K.abs(input[:, 1:, :, :] - input[:, :-1, :, :])\n",
        "    dW = K.abs(input[:, :, 1:, :] - input[:, :, :-1, :])\n",
        "    dH = dH * dH\n",
        "    dW = dW * dW\n",
        "    loss = K.sum(dH) + K.sum(dW)\n",
        "    return loss\n",
        "def levelsetLoss(y_true, y_pred, ratio = 0.001):\n",
        "    #print(\"go\")\n",
        "    outshape = y_pred.shape\n",
        "    tarshape = y_true.shape\n",
        "    multi = y_true*y_pred\n",
        "    c_numerator = K.sum(multi, [1,2])\n",
        "    c_denominator = K.sum(y_pred, [1,2])\n",
        "    #print(\"outshape,tarshape,multi.shape,c_numerator.shape, c_denominator.shape\")\n",
        "    #print(outshape,tarshape,multi.shape,c_numerator.shape, c_denominator.shape)\n",
        "    c = c_numerator/c_denominator\n",
        "    #print(\"s\",c.shape)\n",
        "    c = K.reshape(c, (-1, 1, 1,outshape[3])) \n",
        "    #print(\"c.shape: \", c.shape)\n",
        "    plevel = y_true - c\n",
        "    #print(\"plevel: \", plevel)\n",
        "    pLoss = plevel * plevel * y_pred\n",
        "    lossL = K.mean(pLoss)\n",
        "    #print(\"lossL: \", lossL)\n",
        "    lossA = gradientLoss2d(y_pred) * ratio\n",
        "\n",
        "    return lossL  + dice_coef_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)\n",
        "    return loss\n",
        "def confusion(y_true, y_pred):\n",
        "    smooth=1\n",
        "    y_pred_pos = K.clip(y_pred, 0, 1)\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.clip(y_true, 0, 1)\n",
        "    y_neg = 1 - y_pos\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg) \n",
        "    prec = (tp + smooth)/(tp+fp+smooth)\n",
        "    recall = (tp+smooth)/(tp+fn+smooth)\n",
        "    return prec, recall\n",
        "def tp(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    tp = (K.sum(y_pos * y_pred_pos) + smooth)/ (K.sum(y_pos) + smooth) \n",
        "    return tp \n",
        "def tn(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos \n",
        "    tn = (K.sum(y_neg * y_pred_neg) + smooth) / (K.sum(y_neg) + smooth )\n",
        "    return tn \n",
        "def tversky(y_true, y_pred):\n",
        "    smooth=0.0\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    y_pred = y_pred[0]\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "def heviside(x,epsilon=0.1):\n",
        "    return 1/2*(1+2/3.14159*tf.math.atan(x/epsilon))\n",
        "def Active_Contour_Loss(y_true, y_pred): \n",
        "    epison = 0.1\n",
        "    #Drc = (epison / 3.14159) / (epison * epison + y_pred[:,:,:,0] * y_pred[:,:,:,0])\n",
        "    #Hea = 1/2*(1+2/3.14159*tf.math.atan(y_pred[:,:,:,0]/0.1))\n",
        "    Hea = tf.sigmoid(y_pred[:,:,:,0])\n",
        "    mean_in = np.ones((h, w))\n",
        "    mean_out = np.zeros((h, w))\n",
        "\n",
        "    region_in = K.abs(K.mean( Hea * ((y_true[:,:,:,0] - mean_in)**2) ) ) \n",
        "    region_out = K.abs(K.mean( (1-Hea) * ((y_true[:,:,:,0] - mean_out)**2) )) \n",
        "    #region_in + 2*region_out\n",
        "    return  region_in + 2*region_out # 0.5*tf.keras.losses.binary_crossentropy(y_true[:,:,:,0],Hea)\n",
        "def loss_edge(y_true, y_pred):\n",
        "    epison = 1/3.14159\n",
        "    Drc = epison / (3.14159 * (epison * epison + y_pred * y_pred))\n",
        "    x = y_true[:,1:,:,:] - y_true[:,:-1,:,:] # horizontal and vertical directions \n",
        "    y = y_true[:,:,1:,:] - y_true[:,:,:-1,:]\n",
        "    delta_x = x[:,1:,:-2,:]**2\n",
        "    delta_y = y[:,:-2,1:,:]**2\n",
        "    delta_u = K.sqrt(K.abs(delta_x + delta_y))/np.sqrt(2)\n",
        "    return tf.keras.losses.binary_crossentropy(delta_u,Drc[:,1:-1,1:-1,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOEtn8LitnLh"
      },
      "source": [
        "def tv_bce(y_true,y_pred):\n",
        "    x = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:]\n",
        "    y = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "    sum = tf.reduce_sum(tf.abs(x))+tf.reduce_sum(tf.abs(y))\n",
        "    return sum*1e-6+tf.keras.losses.binary_crossentropy(y_true,y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdFtUsZS2lA"
      },
      "source": [
        "#attention gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKz9kO5RS1gu"
      },
      "source": [
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "              padding='same', strides=(1, 1), use_bias=False):\n",
        "\n",
        "    #print(nb_filter)\n",
        "    channel_axis = -1\n",
        "    x = Conv2D(nb_filter, (num_row, num_col),\n",
        "                      strides=strides,\n",
        "                      padding=padding,\n",
        "                      use_bias=use_bias)(x)\n",
        "    #x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Lambda(mvn)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n",
        "    #attention_up_and_concate(conv6,skip2)\n",
        "    data_format='channels_last'\n",
        "\n",
        "    in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    #up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
        "\n",
        "    my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n",
        "    data_format='channels_last'\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
        "\n",
        "    f =add([theta_x, phi_g])\n",
        "    f = Activation(\"relu\")(f)\n",
        "    # branch_0 = conv2d_bn(f, inter_channel//4, 1, 1)\n",
        "\n",
        "    # branch_1 = conv2d_bn(f, inter_channel//5, 1, 1)\n",
        "    # branch_1 = conv2d_bn(branch_1, inter_channel//4, 3, 3)\n",
        "\n",
        "    # branch_2 = conv2d_bn(f, inter_channel//5, 1, 1)\n",
        "    # branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "    # branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "\n",
        "    # branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(f)\n",
        "    # branch_3 = conv2d_bn(branch_3, inter_channel//4, 1, 1)\n",
        "\n",
        "    # x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=-1)\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "    #rate = Activation(heviside())(psi_f)\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex6okk6veCyB"
      },
      "source": [
        "#callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWLUi7qM2nq"
      },
      "source": [
        "class lr_scheduler(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if epoch == 59 or epoch == 79:\n",
        "      current_lr = K.eval(self.model.optimizer.lr)\n",
        "      current_lr = current_lr / 10\n",
        "      K.set_value(self.model.optimizer.lr, current_lr)\n",
        "      print(K.eval(self.model.optimizer.lr))\n",
        "\n",
        "\n",
        "class visualize(tf.keras.callbacks.Callback):\n",
        "    def __init__(self,img,mask):\n",
        "        super(visualize, self).__init__()\n",
        "        self.img = img\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "       feature_maps = self.model.predict(img)\n",
        "       fm = feature_maps[0][0]\n",
        "       fmh = heviside(fm)\n",
        "       #print(fm.shape)\n",
        "       square = 2\n",
        "       print(\"------------------------\")\n",
        "       #print(feature_maps[-1][0,:3,:3,0])\n",
        "       print(\"-------------------------\")\n",
        "       #print(feature_maps[0][0,:3,:3,0])\n",
        "       plt.subplot(132),plt.imshow(fmh[:,:,0],cmap = 'gray')\n",
        "       plt.subplot(133),plt.imshow(fm[:,:,0],cmap = 'gray')\n",
        "       plt.subplot(131),plt.imshow(mask[0,:,:,0],cmap = 'gray')\n",
        "       plt.show()\n",
        "      #  for fmap in feature_maps[1:]:\n",
        "      #       ix = 1\n",
        "      #       for _ in range(square):\n",
        "      #           for _ in range(square):\n",
        "      #               # specify subplot and turn of axis\n",
        "      #               ax = plt.subplot(square, square, ix)\n",
        "      #               ax.set_xticks([])\n",
        "      #               ax.set_yticks([])\n",
        "      #               # plot filter channel in grayscale\n",
        "      #               if ix > fmap.shape[-1]:\n",
        "      #                   continue\n",
        "      #               plt.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "      #               ix += 1\n",
        "      #       plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0QEKvbCdEox"
      },
      "source": [
        "#efficient Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUse0GipHrr"
      },
      "source": [
        "def efficient_unet(image_shape,num_class,weights=None):\n",
        "  data = Input(shape=image_shape)\n",
        "  mvn0 = Lambda(mvn)(data)\n",
        "  conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "  conv1 = Lambda(mvn)(conv1)\n",
        "  conv1 = Activation('relu')(conv1)\n",
        "  conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "  conv1 = Lambda(mvn)(conv1)\n",
        "  conv1 = Activation('relu')(conv1)\n",
        "  base =  app.efficientnet.EfficientNetB4(include_top=False, weights=None, input_tensor= conv1)\n",
        "  x=base.get_layer(\"top_activation\").output #7x7x1280 chia 32\n",
        "  skip1=base.get_layer(\"block6a_expand_activation\").output \n",
        "  skip2 =base.get_layer(\"block4a_expand_activation\").output \n",
        "  skip3 = base.get_layer(\"block3a_expand_activation\").output \n",
        "  skip4 = base.get_layer(\"block2a_expand_activation\").output \n",
        "  skip5 = base.layers[9].output \n",
        "  model = decode_unet(x,data,skip1,skip2,skip3,skip4,skip5)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAg3HIMGiHfw"
      },
      "source": [
        "def xcep_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.Xception(include_top=False, weights=None, input_tensor= conv1)\n",
        "    x=base.get_layer(\"block14_sepconv2_act\").output #chia 32\n",
        "    skip1=base.get_layer(\"block13_sepconv2_bn\").output #chia 16\n",
        "    skip2 =base.get_layer(\"block4_sepconv2_bn\").output  #chia 8\n",
        "    skip3 = base.get_layer(\"block3_sepconv2_bn\").output \n",
        "    skip3 = ZeroPadding2D(((0,1),(0,1)))(skip3)\n",
        "    skip4 = base.get_layer(\"block2_sepconv2_bn\").output\n",
        "    skip4 = ZeroPadding2D(((1,2),(1,2)))(skip4)\n",
        "    skip5 =conv1\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0DUMW6vXAk"
      },
      "source": [
        "def block_inception_a(input):\n",
        "    inter_channel = input.get_shape().as_list()[3]\n",
        "    branch_0 = conv2d_bn(input, inter_channel//4, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, inter_channel//5, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, inter_channel//4, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, inter_channel//5, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, inter_channel//4, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=-1)\n",
        "    return x\n",
        "def incep_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.InceptionV3(include_top=False, weights=None, input_tensor= data)\n",
        "    x=base.layers[-3].output #chia 32\n",
        "    x = ZeroPadding2D(((0,1),(0,1)))(x)\n",
        "    skip1=base.layers[228].output #chia 16\n",
        "    skip2 =base.layers[86].output  #chia 8\n",
        "    skip2 = Cropping2D(((0,1),(0,1)))(skip2)\n",
        "    skip3 = base.layers[16].output \n",
        "    skip3 = Cropping2D(((2,2),(2,2)))(skip3)\n",
        "    #skip3 = ZeroPadding2D(((0,1),(0,1)))(skip3)\n",
        "    skip4 = base.layers[9].output\n",
        "    #skip4 = ZeroPadding2D(((1,2),(1,2)))(skip4)\n",
        "    skip5 = base.layers[1].output\n",
        "    print(\"output: \",x.shape)\n",
        "    print(\"skip1 shape: \",skip1.shape)\n",
        "    print(\"skip2 shape: \",skip2.shape)\n",
        "    print(\"skip3 shape: \",skip3.shape)\n",
        "    print(\"skip4 shape: \",skip4.shape)\n",
        "    print(\"skip5 shape: \",skip5.shape)\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5 = None)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ShTOBpC5ec"
      },
      "source": [
        "def mobile_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.MobileNet(include_top=False, weights=None, input_tensor= conv1)\n",
        "    x=base.layers[-7].output #chia 32\n",
        "    #x = ZeroPadding2D(((0,1),(0,1)))(x)\n",
        "    skip1=base.layers[73+7].output #chia 16\n",
        "    skip2 =base.layers[36+7].output  #chia 8\n",
        "    skip3 = base.layers[23+7].output #chia4\n",
        "    skip4 = base.layers[10+7].output  #chia2\n",
        "    skip5 = conv1\n",
        "    print(\"output: \",x.shape)\n",
        "    print(\"skip1 shape: \",skip1.shape)\n",
        "    print(\"skip2 shape: \",skip2.shape)\n",
        "    print(\"skip3 shape: \",skip3.shape)\n",
        "    print(\"skip4 shape: \",skip4.shape)\n",
        "    print(\"skip5 shape: \",skip5.shape)\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz7l78gsbCCw"
      },
      "source": [
        "def unet(input_size = (192,288,3),classnum=2,pretrained_weights = None):\n",
        "    data = Input(shape=input_size, dtype='float', name='data')\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = block_inception_a(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n",
        "    conv2 = Lambda(mvn)(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    conv2 = block_inception_a(conv2)\n",
        "    conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n",
        "    conv2 = Lambda(mvn)(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n",
        "    conv3 = Lambda(mvn)(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = block_inception_a(conv3)\n",
        "    conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n",
        "    conv3 = Lambda(mvn)(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n",
        "    conv4 = Lambda(mvn)(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    conv4 = block_inception_a(conv4)\n",
        "    conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n",
        "    conv4 = Lambda(mvn)(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n",
        "    conv5 = Lambda(mvn)(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    conv5 = block_inception_a(conv5)\n",
        "    conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n",
        "    conv5 = Lambda(mvn)(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    #pool5 = MaxPooling2D(pool_size=(2, 2))(drop5)\n",
        "\n",
        "    # convx = Conv2D(1024, 3,  padding = 'same')(pool5)\n",
        "    # convx = Lambda(mvn)(convx)\n",
        "    # convx = Activation('relu')(convx)\n",
        "    # convx = Conv2D(1024, 3,  padding = 'same')(convx)\n",
        "    # convx = Lambda(mvn)(convx)\n",
        "    # convx = Activation('relu')(convx)\n",
        "    # dropx = Dropout(0.5)(convx)\n",
        "\n",
        "\n",
        "    model = decode_unet(drop5,data,conv4,conv3,conv2,conv1,skip5 = None)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veBOYeZyrhBS"
      },
      "source": [
        "def decode_unet(x,data,skip1,skip2,skip3,skip4,skip5):\n",
        "    if skip5 is not None:\n",
        "        #filters = [1024,728,256,128,64]\n",
        "        filters = [1024,512,256,128,64]\n",
        "    else:\n",
        "        filters = [512,256,128,64]\n",
        "    merge6 = attention_up_and_concate(x,skip1)\n",
        "    conv6 = Conv2D(filters[0], 3,  padding = 'same')(merge6)\n",
        "    conv6 = Lambda(mvn)(conv6)\n",
        "    conv6 = Activation('relu')(conv6)\n",
        "    conv6 = Conv2D(filters[0], 3,  padding = 'same')(conv6)\n",
        "    conv6 = Lambda(mvn)(conv6)\n",
        "    conv6 = Activation('relu')(conv6)\n",
        "\n",
        "\n",
        "    \n",
        "    merge7 = attention_up_and_concate(conv6,skip2)\n",
        "    conv7 = Conv2D(filters[1], 3,  padding = 'same')(merge7)\n",
        "    conv7 = Lambda(mvn)(conv7)\n",
        "    conv7 = Activation('relu')(conv7)\n",
        "    conv7 = Conv2D(filters[1], 3,  padding = 'same')(conv7)\n",
        "    conv7 = Lambda(mvn)(conv7)\n",
        "    conv7 = Activation('relu')(conv7)\n",
        "\n",
        "    \n",
        "    merge8 = attention_up_and_concate(conv7,skip3)\n",
        "    conv8 = Conv2D(filters[2], 3,  padding = 'same')(merge8)\n",
        "    conv8 = Lambda(mvn)(conv8)\n",
        "    conv8 = Activation('relu')(conv8)\n",
        "    conv8 = Conv2D(filters[2], 3,  padding = 'same')(conv8)\n",
        "    conv8 = Lambda(mvn)(conv8)\n",
        "    conv8 = Activation('relu')(conv8)\n",
        "\n",
        "\n",
        "     \n",
        "    merge9 = attention_up_and_concate(conv8,skip4)\n",
        "    conv9 = Conv2D(filters[3], 3,  padding = 'same')(merge9)\n",
        "    conv9 = Lambda(mvn)(conv9)\n",
        "    conv9 = Activation('relu')(conv9)\n",
        "    conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "    \n",
        "    if skip5 is not None:\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        merge10 = attention_up_and_concate(conv9,skip5)\n",
        "        conv10 = Conv2D(filters[4], 3,  padding = 'same')(merge10)\n",
        "        conv10 = Lambda(mvn)(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(filters[4], 3,  padding = 'same')(conv10)\n",
        "        #conv10 = Activation('relu')(conv10)\n",
        "        edge_out = Conv2D(1, 1,name = \"output1\")(conv10)\n",
        "        conv10 = Lambda(mvn)(conv10)\n",
        "        #conv10 = BatchNormalization()(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(2, 3,  padding = 'same')(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(1, 1,name = \"main_output\")(conv10)\n",
        "        #out = tf.keras.layers.Activation(\"sigmoid\",name = \"main_output\")(conv10)\n",
        "        model = Model(inputs = data, outputs = [conv10,edge_out])\n",
        "    else:\n",
        "        #conv9 = Lambda(mvn)(conv9)\n",
        "        #conv9 = Activation('relu')(conv9)\n",
        "        #conv9 = UpSampling2D()(conv9)\n",
        "        #conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "        edge_out = Conv2D(1, 1,name = \"output1\")(conv9)\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv9 = Conv2D(2, 3,  padding = 'same')(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv10 = Conv2D(1, 1,name = \"main_output\")(conv9)\n",
        "        print(\"output shape:\",conv10.shape)\n",
        "        #out = tf.keras.layers.Activation(\"sigmoid\",name = \"main_output\")(conv10)\n",
        "        model = Model(inputs = data, outputs = [conv10,edge_out])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiM8Ct8QpNX8"
      },
      "source": [
        "test_model = app.InceptionV3()\n",
        "tf.keras.utils.plot_model(\n",
        "    test_model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d707bUi8U-y6"
      },
      "source": [
        "# Fit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4OOhfQjWHlO"
      },
      "source": [
        "Epoch 60/80\n",
        "500/500 [==============================] - 288s 576ms/step - loss: 0.3507 - acc: 0.9603 - dice_coef: 0.9069 - jaccard_coef: 0.8409 - val_loss: 0.4036 - val_acc: 0.9290 - val_dice_coef: 0.8515 - val_jaccard_coef: 0.7673"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5EfZgNlGmQN"
      },
      "source": [
        " #from itertools import izip\n",
        "generator_x = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect',\n",
        "    #brightness_range = (0.9,1.1),\n",
        ")\n",
        "generator_y = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    #brightness_range = (1.0,1.0),\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect'\n",
        ")\n",
        "seed = 1234\n",
        "batch = 4\n",
        "\n",
        "x_gen = generator_x.flow(imgs, batch_size = batch, shuffle = False, seed = seed)\n",
        "y_gen = generator_y.flow(masks, batch_size = batch, shuffle = False, seed = seed)\n",
        "train_generator = zip(x_gen, y_gen)\n",
        "input_shape = (h, w, 3)\n",
        "img = imgs[6:7]\n",
        "mask = masks[6:7]\n",
        "plt.imshow(img[0,:,:,:].astype(\"uint8\"),cmap='gray')\n",
        "plt.show()\n",
        "model = unet(input_shape,2)\n",
        "#model.load_weights(\"/content/weights_save/ACLN.77_0.708.h5\")\n",
        "model.compile(optimizer = SGD(lr = 0.01, momentum = 0.9), loss = {\"main_output\":Active_Contour_Loss,\"output1\":loss_edge}, \n",
        "              loss_weights={'main_output': 1., 'output1': 0.2},\n",
        "              metrics = {\"main_output\":[dice_coef]})\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights_save/ACLN.{epoch:02d}_{val_main_output_dice_coef:.3f}.h5', \n",
        "                             monitor='val_main_output_dice_coef',save_best_only=True, verbose=1, save_weights_only=True, mode='max')\n",
        "#lr_decay = lr_scheduler()\n",
        "callback_list = [visualize(img,mask)]\n",
        "history = model.fit(train_generator, steps_per_epoch = imgs.shape[0], epochs = 50, \n",
        "                    validation_data = (img_dev, mask_dev),callbacks = callback_list,verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdmlP0Jqah60",
        "outputId": "e7e77080-e714-41dd-fcce-997b27171916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(max(history.history['val_main_output_dice_coef']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7273074388504028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OZkHcWPsFr1"
      },
      "source": [
        "Ket qua\n",
        "Dung ham heviside active contour loss tỉ lệ 1 -2 \n",
        "\n",
        "Fine tune từ tập pseudo\n",
        "\n",
        "loss: 0.0579 - accuracy: 0.9366 - dice_coef: 0.8038 - val_loss: 0.0918 - val_accuracy: 0.9235 - val_dice_coef: 0.7649\n",
        "\n",
        "\n",
        "\n",
        "chạy từ đầu ảnh doctor 80 epoch step  = 100/epoch\n",
        "\n",
        "loss: 0.0482 - accuracy: 0.9437 - dice_coef: 0.8340 - val_loss: 0.1061 - val_accuracy: 0.9329 - val_dice_coef: 0.7451\n",
        "\n",
        "\n",
        "chạy từ đầu ảnh pseudo 400step/epoch\n",
        "\n",
        "\n",
        "loss: 0.0359 - accuracy: 0.9481 - dice_coef: 0.8590 - val_loss: 0.1045 - val_accuracy: 0.9298 - val_dice_coef: 0.7416"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eug0by9N6eor"
      },
      "source": [
        "#visualize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQpMuGw-Wca"
      },
      "source": [
        "val_main_output_dice_coefmodel = unet((352,352,3),2,\"/content/drive/My Drive/weight_infection_acl/unet.23_0.72.h5\")\n",
        "mask_pred = model.predict(imgs)\n",
        "mask_copy = mask_pred.copy()\n",
        "mask_pred = heviside(mask_pred,0.01)\n",
        "#mask_pred[mask_pred<0] = 0\n",
        "#mask_pred[mask_pred>0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk1CCkIU_R3o"
      },
      "source": [
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(masks[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FC_3D77Dh0M"
      },
      "source": [
        "epison = 1/3.14159\n",
        "Drc = epison / (3.14159 * (epison * epison + mask_copy[:,:,:,:] * mask_copy[:,:,:,:]))\n",
        "print(K.mean(tf.keras.losses.binary_crossentropy(edge,Drc)))\n",
        "plt.imshow(Drc[1,:,:,0],cmap= 'gray')\n",
        "plt.xticks(np.arange(0, 353, 50))\n",
        "plt.show()   \n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "print(edge[1,:,:,0].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zbV6bj_PaM"
      },
      "source": [
        "x = masks[:,1:,:,:] - masks[:,:-1,:,:] # horizontal and vertical directions \n",
        "y = masks[:,:,1:,:] - masks[:,:,:-1,:]\n",
        "\n",
        "\n",
        "delta_x = x[:,1:,:-2,:]**2\n",
        "delta_y = y[:,:-2,1:,:]**2\n",
        "delta_u = K.sqrt(K.abs(delta_x + delta_y))/np.sqrt(2)\n",
        "print(delta_u.numpy().max())\n",
        "\n",
        "plt.imshow(delta_u[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH8fKNgkU-Nw"
      },
      "source": [
        "def dice_coef2(y_true, y_pred, smooth=1.0):\n",
        "    '''Average dice coefficient per batch.'''\n",
        "    axes = (1,2,3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes) #AhopM\n",
        "    summation = K.sum(y_true + y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss2(y_true, y_pred):\n",
        "    return 1-dice_coef2(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVxvlUa5vwdj"
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/weight_infection_acl/unet.55_0.74.h5\")\n",
        "mask_pred = model.predict(img_dev)\n",
        "#mask_pred = heviside(mask_pred,epsilon=0.01)\n",
        "mask_pred[mask_pred<0] = 0\n",
        "mask_pred[mask_pred>0] = 1\n",
        "print(dice_coef2(mask_dev,mask_pred))\n",
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(mask_dev[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950EqpOh9Gwn"
      },
      "source": [
        "import tensorflow.keras.applications as app\n",
        "model = app.MobileNet()\n",
        "for count,layer in enumerate(model.layers):\n",
        "\t# check for convolutional layer\n",
        "\t#if 'conv' not in layer.name:\n",
        "\t#\tcontinue\n",
        "\t# get filter weights\n",
        "\tprint(count, layer.name)\n",
        "\t#filters, biases = layer.get_weights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51Rz4w_C7xB"
      },
      "source": [
        "ixs = [2, 5, 9, 91, 94,97]\n",
        "outputs = [model.layers[i].output for i in ixs]\n",
        "model = Model(inputs=model.inputs, outputs=outputs)\n",
        "pyplot.imshow(imgs[0,:,:,:].astype(\"uint8\"),cmap='gray')\n",
        "pyplot.show()\n",
        "feature_maps = model.predict(imgs[:1,:,:,:])\n",
        "# plot the output from each block\n",
        "square = 2\n",
        "for fmap in feature_maps:\n",
        "    print(fmap.shape)\n",
        "    ix = 1\n",
        "    for _ in range(square):\n",
        "        for _ in range(square):\n",
        "            # specify subplot and turn of axis\n",
        "            ax = pyplot.subplot(square, square, ix)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # plot filter channel in grayscale\n",
        "            if ix > fmap.shape[-1]:\n",
        "                continue\n",
        "            pyplot.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "            ix += 1\n",
        "\t# show the figure\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnKx3sVwjxRL"
      },
      "source": [
        "#plt.figure(1)\n",
        "#plt.subplot(121,aspect='auto')\n",
        "y=history.history['val_dice_coef']\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.title('Model DCS')\n",
        "plt.ylabel('DCS')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#plt.subplot(122,aspect='auto')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}