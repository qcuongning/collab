{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thyroid_nod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcuongning/collab/blob/main/Thyroid_nodule_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhF704nMmIx"
      },
      "source": [
        "Với các hàm cần sử dụng backend Keras mà bị lỗi K not contribute cần đổi về keras==2.2.4\n",
        "\n",
        "\n",
        "The codebase is heavily inspired by the [respotory](https://github.com/qubvel/efficientnet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80XmdWXlUgZG"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnbEu1yz0PKx"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications as app\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "from zipfile import ZipFile\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEODECWeDwKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "c5099bc7-b123-44f6-862f-33d1a0b40df5"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-209d2e5a43b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BmpPr1ID0Mz"
      },
      "source": [
        "file_id = '1bbKAqUuk7Y1q3xsDSwP07oOXN_GL3SQM'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('COVID-SemiSegz')\n",
        "with ZipFile('COVID-SemiSegz', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9wexv7y7QeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524c12b1-dccd-46c0-d251-aabde152bc96"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc20AZFtGeyk"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/COVID-SemiSeg.zip /content/\n",
        "with ZipFile('COVID-SemiSeg.zip', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOs9YUGVujtH"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/thyroid/training_data.zip /content/\n",
        "with ZipFile('training_data.zip', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNhqAQK442Z"
      },
      "source": [
        "file_name = 'weights_save'\n",
        "if not os.path.exists(file_name):\n",
        "  os.mkdir(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDGT7k5XUtJY"
      },
      "source": [
        "# Initial Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS-_PJSBTLfr"
      },
      "source": [
        "lấy các cặp ảnh và mask\n",
        "\n",
        "ảnh resize về 192x288\n",
        "\n",
        "mask là binary\n",
        "đầu ra imgs , masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFXg1utzw1e9"
      },
      "source": [
        "ff = os.listdir(\"thyroid\")\n",
        "folder = \"thyroid/\"\n",
        "imgs = []\n",
        "masks = []\n",
        "labels = []\n",
        "# h, w = 352 // 2, 512 // 2\n",
        "for count, f in enumerate(ff):\n",
        "    rd_num = np.random.uniform(0.7, 1)\n",
        "    if f.find(\".jpg\") > 0:\n",
        "        img = cv2.imread(folder + f)\n",
        "        # img = cv2.resize(img, (w, h))\n",
        "        ix_number = f.find(\"_\")\n",
        "        rep = f[ix_number + 1:ix_number + 2]\n",
        "        if ix_number < 0:\n",
        "            ix_number = f.find(\".\")\n",
        "        number = f[:ix_number]\n",
        "        if number == \"127\" or number == '54' or number == '165' or number == '176' or number == '203' or number == '205' or number == '166' or number == '197':\n",
        "            continue\n",
        "        # print(number)\n",
        "        root = ET.parse(folder + number + \".xml\").getroot()\n",
        "        # print(\"so anh: \",len(root.findall(\"mark\")))\n",
        "        lb = (root.find(\"tirads\").text)\n",
        "        if lb in ('4a','4b','4c','5'):\n",
        "            tt = 1\n",
        "        else:\n",
        "            tt = 0\n",
        "        for neighbor in root.findall(\"mark\"):\n",
        "            if rep != neighbor.find(\"image\").text:\n",
        "                continue\n",
        "            svg = neighbor.find(\"svg\").text\n",
        "            if svg is None:\n",
        "                continue\n",
        "            ss = eval(svg)\n",
        "            for s in ss:\n",
        "                contour = []\n",
        "                for point in s[\"points\"]:\n",
        "                    x = point[\"x\"]\n",
        "                    y = point['y']\n",
        "                    contour.append([[x, y]])\n",
        "                contour = np.asarray(contour)\n",
        "                rect = cv2.boundingRect(contour)\n",
        "                x,y,w,h = rect\n",
        "                blob= img[y-h//10:y+h+h//10,x-w//10:x+w+w//10]\n",
        "                blob = cv2.resize(blob,(96,96))\n",
        "                imgs.append(blob)\n",
        "                labels.append(tt)\n",
        "imgs = np.asarray(imgs,dtype = np.float32)\n",
        "labels = np.asarray(labels,dtype = np.float32)\n",
        "from sklearn.utils import shuffle\n",
        "imgs, labels = shuffle(imgs, labels)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCGauKAH9HKJ"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical  \n",
        "labels = to_categorical(labels,2)\n",
        "n = 550\n",
        "x_train = imgs[:n]\n",
        "x_dev = imgs[n:]\n",
        "\n",
        "y_train = labels[:n]\n",
        "y_dev = labels[n:]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4efkGcj6nHv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " #from itertools import izip\n",
        "generator_x = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect',\n",
        "    #brightness_range = (0.9,1.1),\n",
        ")\n",
        "generator_y = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    #brightness_range = (1.0,1.0),\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect'\n",
        ")\n",
        "seed = 1234\n",
        "batch = 1\n",
        "#X_train, X_test, y_train, y_test = train_test_split(imgs, masks, test_size=0.1)\n",
        "x_gen = generator_x.flow(X_train, batch_size = batch, shuffle = False, seed = seed)\n",
        "y_gen = generator_y.flow(y_train, batch_size = batch, shuffle = False, seed = seed)\n",
        "train_generator = zip(x_gen, y_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d707bUi8U-y6"
      },
      "source": [
        "# Fit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4OOhfQjWHlO"
      },
      "source": [
        "Epoch 60/80\n",
        "500/500 [==============================] - 288s 576ms/step - loss: 0.3507 - acc: 0.9603 - dice_coef: 0.9069 - jaccard_coef: 0.8409 - val_loss: 0.4036 - val_acc: 0.9290 - val_dice_coef: 0.8515 - val_jaccard_coef: 0.7673"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIz-HC0MEhW9",
        "outputId": "1da1fc32-a940-4d46-ba12-fae70ec3aa6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrain.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 102, 102, 3)  0           input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 48, 48, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 48, 48, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 48, 48, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 50, 50, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 24, 24, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 24, 24, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 24, 24, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 24, 24, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 24, 24, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 24, 24, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 24, 24, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 24, 24, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 24, 24, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 24, 24, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 24, 24, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 24, 24, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 24, 24, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 24, 24, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 24, 24, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 24, 24, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 24, 24, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 24, 24, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 24, 24, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 24, 24, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 12, 12, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 12, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 12, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 12, 12, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 12, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 12, 12, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 12, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 12, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 12, 12, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 12, 12, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 12, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 12, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 12, 12, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 12, 12, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 12, 12, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 12, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 12, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 12, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 12, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 12, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 12, 12, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 12, 12, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 6, 6, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 6, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 6, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 6, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 6, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 6, 6, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 6, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 6, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 6, 6, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 6, 6, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 6, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 6, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 6, 6, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 6, 6, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 6, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 6, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 6, 6, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 6, 6, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 6, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 6, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 6, 6, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 6, 6, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 6, 6, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 6, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 6, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 6, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 6, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 6, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 6, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 6, 6, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 6, 6, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 3, 3, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 3, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 3, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 3, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 3, 3, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 3, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 3, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 3, 3, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 3, 3, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 3, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 3, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 3, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 3, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 3, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 3, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 3, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 3, 3, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 3, 3, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5EfZgNlGmQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d547f6-c680-4867-96eb-09f864905318"
      },
      "source": [
        "input_ten=Input(shape=(96,96,3))\n",
        "pretrain = app.ResNet50(include_top = False, weights='imagenet', input_tensor=input_ten)\n",
        "pre_out=pretrain.get_layer(\"conv3_block4_out\").output\n",
        "flat=Flatten()(pre_out)\n",
        "predict=Dense(256,activation='relu')(flat)\n",
        "predict=Dense(2,activation='sigmoid')(predict)\n",
        "model=Model(inputs=input_ten,outputs=predict)\n",
        "sgd = Adam(lr = 1e-5)\n",
        "\n",
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#lr_decay = lr_scheduler()\n",
        "history = model.fit(x_train,y_train,batch_size=32, epochs = 50, \n",
        "                    validation_data = (x_dev, y_dev))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8252 - accuracy: 0.5964 - val_loss: 0.7342 - val_accuracy: 0.5660\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.5297 - accuracy: 0.7564 - val_loss: 0.7285 - val_accuracy: 0.5660\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3837 - accuracy: 0.8564 - val_loss: 0.9003 - val_accuracy: 0.5660\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.2730 - accuracy: 0.9582 - val_loss: 0.7849 - val_accuracy: 0.5566\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.2060 - accuracy: 0.9836 - val_loss: 1.1486 - val_accuracy: 0.5660\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1526 - accuracy: 0.9891 - val_loss: 0.8269 - val_accuracy: 0.5660\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.5660\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 0.5849\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.6038\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.5755\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.5943\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.6226\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.6226\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.6321\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.6321\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.7971 - val_accuracy: 0.6321\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.6321\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.6415\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.6415\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.8409 - val_accuracy: 0.6226\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.6226\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.6132\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9165 - val_accuracy: 0.6321\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.6509\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8448 - val_accuracy: 0.6226\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.8923 - val_accuracy: 0.6226\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.6226\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.6226\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.6415\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.6226\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.6132\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9725 - val_accuracy: 0.6415\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.6321\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.6415\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.6226\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8785 - val_accuracy: 0.6415\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.6226\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.6321\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9440 - val_accuracy: 0.6321\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.6321\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.6321\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9235 - val_accuracy: 0.6321\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.6132\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.6509\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.6321\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.6321\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.6415\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.6226\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.6321\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.6321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzeMOEjzHmq_"
      },
      "source": [
        "Epoch 49/50\n",
        "35/35 [==============================] - 1s 23ms/step - loss: 5.8039e-05 - accuracy: 1.0000 - val_loss: 2.5970 - val_accuracy: 0.7075\n",
        "\n",
        "pre_out=pretrain.get_layer(\"conv3_block4_out\").output\n",
        "flat=Flatten()(pre_out)\n",
        "predict=Dense(256,activation='relu')(flat)\n",
        "predict=Dense(2,activation='sigmoid')(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eug0by9N6eor"
      },
      "source": [
        "#visualize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQpMuGw-Wca"
      },
      "source": [
        "val_main_output_dice_coefmodel = unet((352,352,3),2,\"/content/drive/My Drive/weight_infection_acl/unet.23_0.72.h5\")\n",
        "mask_pred = model.predict(imgs)\n",
        "mask_copy = mask_pred.copy()\n",
        "mask_pred = heviside(mask_pred,0.01)\n",
        "#mask_pred[mask_pred<0] = 0\n",
        "#mask_pred[mask_pred>0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk1CCkIU_R3o"
      },
      "source": [
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(masks[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FC_3D77Dh0M"
      },
      "source": [
        "epison = 1/3.14159\n",
        "Drc = epison / (3.14159 * (epison * epison + mask_copy[:,:,:,:] * mask_copy[:,:,:,:]))\n",
        "print(K.mean(tf.keras.losses.binary_crossentropy(edge,Drc)))\n",
        "plt.imshow(Drc[1,:,:,0],cmap= 'gray')\n",
        "plt.xticks(np.arange(0, 353, 50))\n",
        "plt.show()   \n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "print(edge[1,:,:,0].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zbV6bj_PaM"
      },
      "source": [
        "x = masks[:,1:,:,:] - masks[:,:-1,:,:] # horizontal and vertical directions \n",
        "y = masks[:,:,1:,:] - masks[:,:,:-1,:]\n",
        "\n",
        "\n",
        "delta_x = x[:,1:,:-2,:]**2\n",
        "delta_y = y[:,:-2,1:,:]**2\n",
        "delta_u = K.sqrt(K.abs(delta_x + delta_y))/np.sqrt(2)\n",
        "print(delta_u.numpy().max())\n",
        "\n",
        "plt.imshow(delta_u[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH8fKNgkU-Nw"
      },
      "source": [
        "def dice_coef2(y_true, y_pred, smooth=1.0):\n",
        "    '''Average dice coefficient per batch.'''\n",
        "    axes = (1,2,3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes) #AhopM\n",
        "    summation = K.sum(y_true + y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss2(y_true, y_pred):\n",
        "    return 1-dice_coef2(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVxvlUa5vwdj"
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/weight_infection_acl/unet.55_0.74.h5\")\n",
        "mask_pred = model.predict(img_dev)\n",
        "#mask_pred = heviside(mask_pred,epsilon=0.01)\n",
        "mask_pred[mask_pred<0] = 0\n",
        "mask_pred[mask_pred>0] = 1\n",
        "print(dice_coef2(mask_dev,mask_pred))\n",
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(mask_dev[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950EqpOh9Gwn"
      },
      "source": [
        "import tensorflow.keras.applications as app\n",
        "model = app.MobileNet()\n",
        "for count,layer in enumerate(model.layers):\n",
        "\t# check for convolutional layer\n",
        "\t#if 'conv' not in layer.name:\n",
        "\t#\tcontinue\n",
        "\t# get filter weights\n",
        "\tprint(count, layer.name)\n",
        "\t#filters, biases = layer.get_weights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51Rz4w_C7xB"
      },
      "source": [
        "ixs = [2, 5, 9, 91, 94,97]\n",
        "outputs = [model.layers[i].output for i in ixs]\n",
        "model = Model(inputs=model.inputs, outputs=outputs)\n",
        "pyplot.imshow(imgs[0,:,:,:].astype(\"uint8\"),cmap='gray')\n",
        "pyplot.show()\n",
        "feature_maps = model.predict(imgs[:1,:,:,:])\n",
        "# plot the output from each block\n",
        "square = 2\n",
        "for fmap in feature_maps:\n",
        "    print(fmap.shape)\n",
        "    ix = 1\n",
        "    for _ in range(square):\n",
        "        for _ in range(square):\n",
        "            # specify subplot and turn of axis\n",
        "            ax = pyplot.subplot(square, square, ix)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # plot filter channel in grayscale\n",
        "            if ix > fmap.shape[-1]:\n",
        "                continue\n",
        "            pyplot.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "            ix += 1\n",
        "\t# show the figure\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnKx3sVwjxRL"
      },
      "source": [
        "#plt.figure(1)\n",
        "#plt.subplot(121,aspect='auto')\n",
        "y=history.history['val_dice_coef']\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.title('Model DCS')\n",
        "plt.ylabel('DCS')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#plt.subplot(122,aspect='auto')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}