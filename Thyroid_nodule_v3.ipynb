{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thyroid_nod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcuongning/collab/blob/main/Thyroid_nodule_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhF704nMmIx"
      },
      "source": [
        "Với các hàm cần sử dụng backend Keras mà bị lỗi K not contribute cần đổi về keras==2.2.4\n",
        "\n",
        "\n",
        "The codebase is heavily inspired by the [respotory](https://github.com/qubvel/efficientnet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80XmdWXlUgZG"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnbEu1yz0PKx"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import applications as app\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "from zipfile import ZipFile\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEODECWeDwKL"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BmpPr1ID0Mz"
      },
      "source": [
        "file_id = '1bbKAqUuk7Y1q3xsDSwP07oOXN_GL3SQM'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('COVID-SemiSegz')\n",
        "with ZipFile('COVID-SemiSegz', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9wexv7y7QeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c85b219-b00e-4131-bd21-833a06723ff5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc20AZFtGeyk"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/thyroid/crop_thyroid.zip /content/\n",
        "with ZipFile('crop_thyroid.zip', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOs9YUGVujtH"
      },
      "source": [
        "#su dung khi dataset o trong drive neu khong bo qua\n",
        "%cp drive/My\\ Drive/thyroid/training_data.zip /content/\n",
        "with ZipFile('training_data.zip', 'r') as tt:\n",
        "  tt.extractall(\"\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TNhqAQK442Z"
      },
      "source": [
        "file_name = 'weights_save'\n",
        "if not os.path.exists(file_name):\n",
        "  os.mkdir(file_name)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDGT7k5XUtJY"
      },
      "source": [
        "# Initial Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS-_PJSBTLfr"
      },
      "source": [
        "lấy các cặp ảnh và mask\n",
        "\n",
        "ảnh resize về 192x288\n",
        "\n",
        "mask là binary\n",
        "đầu ra imgs , masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wZcsYjiHSzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf9cfbe-692f-4818-b3dc-60dd344e5148"
      },
      "source": [
        "pip install elasticdeform"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticdeform\n",
            "  Downloading https://files.pythonhosted.org/packages/22/6b/fd4693892a2035326c79363f05b6380e46d2f70d11e94d3e1f667c797084/elasticdeform-0.4.7.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from elasticdeform) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from elasticdeform) (1.4.1)\n",
            "Building wheels for collected packages: elasticdeform\n",
            "  Building wheel for elasticdeform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elasticdeform: filename=elasticdeform-0.4.7-cp36-cp36m-linux_x86_64.whl size=72529 sha256=d84b8deae68f523c480b19f3b72e3003df99248bbba3045fd95accec13caa951\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/5e/8a/890fbf14dc7f26d5da56968248eb7b85fd7e72870462e2c3e3\n",
            "Successfully built elasticdeform\n",
            "Installing collected packages: elasticdeform\n",
            "Successfully installed elasticdeform-0.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFXg1utzw1e9"
      },
      "source": [
        "import elasticdeform\n",
        "def GetFiles(path):\n",
        "    file_list, dir_list = [], []\n",
        "    for dir, subdirs, files in os.walk(path):\n",
        "        file_list.extend([FJoin(dir, f) for f in files])\n",
        "        dir_list.extend([FJoin(dir, d) for d in subdirs])\n",
        "    return file_list, dir_list\n",
        "\n",
        "def get_mask(image_name,mask_folder):\n",
        "    mask_path=os.path.join(mask_folder, image_name)\n",
        "    img_mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
        "    img_mask = img_mask/255\n",
        "    img_mask[img_mask<0.5] = 0\n",
        "    img_mask[img_mask>=0.5] = 1\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def build_data(path,mask_folder,edge_folder, csv_path,img_shapes,training = True):\n",
        "  w,h = img_shapes\n",
        "  imgs=[]\n",
        "  masks=[]\n",
        "  edges = []\n",
        "  img_name=[]\n",
        "  if csv_path == None:\n",
        "    img_name = os.listdir(path)\n",
        "  else:\n",
        "    with open(csv_path, 'r') as csvFile:\n",
        "      reader = csv.reader(csvFile)\n",
        "      for row in reader:\n",
        "          img_name.append(row[0])\n",
        "  n = len(img_name)//5\n",
        "  for count,file in enumerate(img_name[:]):\n",
        "        if file.find(\"super\")>0:\n",
        "          continue\n",
        "        fullpath= os.path.join(path,file)\n",
        "        #print(fullpath)\n",
        "        msk=get_mask(file,mask_folder)\n",
        "        if edge_folder is not None:\n",
        "          edge = get_mask(file,edge_folder)\n",
        "          edge=cv2.resize(edge,(w,h))\n",
        "          edges.append(edge)\n",
        "        #msk = msk[:, 50:-50]\n",
        "        msk=cv2.resize(msk,(w,h))\n",
        "        masks.append(msk)\n",
        "        image=cv2.imread(fullpath)\n",
        "        #image = image[:, 50:-50]\n",
        "        #image=image/127.5-1\n",
        "        image=cv2.resize(image,(w,h))\n",
        "        imgs.append(image)\n",
        "        if count%n == 0:\n",
        "          plt.figure(count//n,figsize=(6,8),dpi=100)\n",
        "          plt.subplot(1,2,1).imshow(image,cmap='gray')\n",
        "          plt.contour(msk,colors='r')\n",
        "          #plt.draw()\n",
        "          plt.subplot(1,2,2).imshow(image, cmap = 'gray')\n",
        "          plt.show() \n",
        "        if training:\n",
        "            img2, mask2 = elasticdeform.deform_random_grid([image, msk], sigma=25, points=3)\n",
        "            img3, mask3 = elasticdeform.deform_random_grid([image, msk], sigma=25, points=3)\n",
        "            imgs.append(img2)\n",
        "            masks.append(mask2)\n",
        "            imgs.append(img3)\n",
        "            masks.append(mask3)\n",
        "  imgs=np.asarray(imgs,dtype=np.float).reshape(-1,h,w,3)\n",
        "  masks=np.asarray(masks,dtype=np.float).reshape(-1,h,w,1)\n",
        "  edges=np.asarray(edges,dtype=np.float).reshape(-1,h,w,1)\n",
        "  print(\"shape imgs: \",imgs.shape)\n",
        "  print(\"shape masks: \",masks.shape)\n",
        "  return imgs,masks,edges"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJXIQ68RY5e"
      },
      "source": [
        "w = 352\n",
        "h = 352\n",
        "folder_train = \"/content/training_data/imgs\"\n",
        "#folder_train = \"/content/training_data/imgs\"  # thay folder Doctor -> Pseudo để lấy 1600 ảnh pseudo train\n",
        "mask_train_folder = \"/content/training_data/masks\"\n",
        "edge_train_folder = None\n",
        "\n",
        "#mask_train_folder = \"/content/COVID-SemiSeg/Dataset/TrainingSet/LungInfection-Train/Pseudo-label/GT\"\n",
        "folder_test = \"/content/training_data/imgs_test\"\n",
        "mask_test_folder = \"/content/training_data/masks_test\"\n",
        "edge_dev_folder = None\n",
        "imgs,masks,edge = build_data(folder_train,mask_train_folder,edge_train_folder, None, (w,h),training= False)\n",
        "print(\"---------------------------------------------------------\")\n",
        "img_dev,mask_dev,edge_dev = build_data(folder_test,mask_test_folder,edge_dev_folder, None, (w,h),training=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u0pxsIm6BIe"
      },
      "source": [
        "#loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GFsmYJUVfUO"
      },
      "source": [
        "def mvn(tensor):\n",
        "    '''Performs per-channel spatial mean-variance normalization.'''\n",
        "    epsilon = 1e-6\n",
        "    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n",
        "    std = K.std(tensor, axis=(1,2), keepdims=True)\n",
        "    mvn = (tensor - mean) / (std + epsilon)\n",
        "    \n",
        "    return mvn\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    '''Average dice coefficient per batch.'''\n",
        "    #y_pred = heviside(y_pred,epsilon = 0.01)\n",
        "    axes = (1,2,3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes) #AhopM\n",
        "    summation = K.sum(y_true + y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred, smooth=1.0)\n",
        "def gradientLoss2d(input):\n",
        "    dH = K.abs(input[:, 1:, :, :] - input[:, :-1, :, :])\n",
        "    dW = K.abs(input[:, :, 1:, :] - input[:, :, :-1, :])\n",
        "    dH = dH * dH\n",
        "    dW = dW * dW\n",
        "    loss = K.sum(dH) + K.sum(dW)\n",
        "    return loss\n",
        "def levelsetLoss(y_true, y_pred, ratio = 0.001):\n",
        "    #print(\"go\")\n",
        "    outshape = y_pred.shape\n",
        "    tarshape = y_true.shape\n",
        "    multi = y_true*y_pred\n",
        "    c_numerator = K.sum(multi, [1,2])\n",
        "    c_denominator = K.sum(y_pred, [1,2])\n",
        "    #print(\"outshape,tarshape,multi.shape,c_numerator.shape, c_denominator.shape\")\n",
        "    #print(outshape,tarshape,multi.shape,c_numerator.shape, c_denominator.shape)\n",
        "    c = c_numerator/c_denominator\n",
        "    #print(\"s\",c.shape)\n",
        "    c = K.reshape(c, (-1, 1, 1,outshape[3])) \n",
        "    #print(\"c.shape: \", c.shape)\n",
        "    plevel = y_true - c\n",
        "    #print(\"plevel: \", plevel)\n",
        "    pLoss = plevel * plevel * y_pred\n",
        "    lossL = K.mean(pLoss)\n",
        "    #print(\"lossL: \", lossL)\n",
        "    lossA = gradientLoss2d(y_pred) * ratio\n",
        "\n",
        "    return lossL  + dice_coef_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)\n",
        "    return loss\n",
        "def confusion(y_true, y_pred):\n",
        "    smooth=1\n",
        "    y_pred_pos = K.clip(y_pred, 0, 1)\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.clip(y_true, 0, 1)\n",
        "    y_neg = 1 - y_pos\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg) \n",
        "    prec = (tp + smooth)/(tp+fp+smooth)\n",
        "    recall = (tp+smooth)/(tp+fn+smooth)\n",
        "    return prec, recall\n",
        "def tp(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    tp = (K.sum(y_pos * y_pred_pos) + smooth)/ (K.sum(y_pos) + smooth) \n",
        "    return tp \n",
        "def tn(y_true, y_pred):\n",
        "    smooth = 1\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos \n",
        "    tn = (K.sum(y_neg * y_pred_neg) + smooth) / (K.sum(y_neg) + smooth )\n",
        "    return tn \n",
        "def tversky(y_true, y_pred):\n",
        "    smooth=0.0\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    y_pred = y_pred[0]\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "def heviside(x,epsilon=0.1):\n",
        "    return 1/2*(1+2/3.14159*tf.math.atan(x/epsilon))\n",
        "def Active_Contour_Loss(y_true, y_pred): \n",
        "    epison = 0.1\n",
        "    #Drc = (epison / 3.14159) / (epison * epison + y_pred[:,:,:,0] * y_pred[:,:,:,0])\n",
        "    #Hea = 1/2*(1+2/3.14159*tf.math.atan(y_pred[:,:,:,0]/0.1))\n",
        "    Hea = tf.sigmoid(y_pred[:,:,:,0])\n",
        "    mean_in = np.ones((h, w))\n",
        "    mean_out = np.zeros((h, w))\n",
        "\n",
        "    region_in = K.abs(K.mean( Hea * ((y_true[:,:,:,0] - mean_in)**2) ) ) \n",
        "    region_out = K.abs(K.mean( (1-Hea) * ((y_true[:,:,:,0] - mean_out)**2) )) \n",
        "    #region_in + 2*region_out\n",
        "    return  region_in + 2*region_out # 0.5*tf.keras.losses.binary_crossentropy(y_true[:,:,:,0],Hea)\n",
        "def loss_edge(y_true, y_pred):\n",
        "    epison = 1/3.14159\n",
        "    Drc = epison / (3.14159 * (epison * epison + y_pred * y_pred))\n",
        "    x = y_true[:,1:,:,:] - y_true[:,:-1,:,:] # horizontal and vertical directions \n",
        "    y = y_true[:,:,1:,:] - y_true[:,:,:-1,:]\n",
        "    delta_x = x[:,1:,:-2,:]**2\n",
        "    delta_y = y[:,:-2,1:,:]**2\n",
        "    delta_u = K.sqrt(K.abs(delta_x + delta_y))/np.sqrt(2)\n",
        "    return tf.keras.losses.binary_crossentropy(delta_u,Drc[:,1:-1,1:-1,:])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOEtn8LitnLh"
      },
      "source": [
        "def tv_bce(y_true,y_pred):\n",
        "    x = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:]\n",
        "    y = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "    sum = tf.reduce_sum(tf.abs(x))+tf.reduce_sum(tf.abs(y))\n",
        "    return sum*1e-6+tf.keras.losses.binary_crossentropy(y_true,y_pred)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdFtUsZS2lA"
      },
      "source": [
        "#attention gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKz9kO5RS1gu"
      },
      "source": [
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "              padding='same', strides=(1, 1), use_bias=False):\n",
        "\n",
        "    #print(nb_filter)\n",
        "    channel_axis = -1\n",
        "    x = Conv2D(nb_filter, (num_row, num_col),\n",
        "                      strides=strides,\n",
        "                      padding=padding,\n",
        "                      use_bias=use_bias)(x)\n",
        "    #x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "    x = Lambda(mvn)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n",
        "    #attention_up_and_concate(conv6,skip2)\n",
        "    data_format='channels_last'\n",
        "\n",
        "    in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    #up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
        "\n",
        "    my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n",
        "    data_format='channels_last'\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
        "\n",
        "    f =add([theta_x, phi_g])\n",
        "    f = Activation(\"relu\")(f)\n",
        "    # branch_0 = conv2d_bn(f, inter_channel//4, 1, 1)\n",
        "\n",
        "    # branch_1 = conv2d_bn(f, inter_channel//5, 1, 1)\n",
        "    # branch_1 = conv2d_bn(branch_1, inter_channel//4, 3, 3)\n",
        "\n",
        "    # branch_2 = conv2d_bn(f, inter_channel//5, 1, 1)\n",
        "    # branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "    # branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "\n",
        "    # branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(f)\n",
        "    # branch_3 = conv2d_bn(branch_3, inter_channel//4, 1, 1)\n",
        "\n",
        "    # x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=-1)\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "    #rate = Activation(heviside())(psi_f)\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex6okk6veCyB"
      },
      "source": [
        "#callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWLUi7qM2nq"
      },
      "source": [
        "class lr_scheduler(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if epoch == 59 or epoch == 79:\n",
        "      current_lr = K.eval(self.model.optimizer.lr)\n",
        "      current_lr = current_lr / 10\n",
        "      K.set_value(self.model.optimizer.lr, current_lr)\n",
        "      print(K.eval(self.model.optimizer.lr))\n",
        "\n",
        "\n",
        "class visualize(tf.keras.callbacks.Callback):\n",
        "    def __init__(self,img,mask):\n",
        "        super(visualize, self).__init__()\n",
        "        self.img = img\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        feature_maps = self.model.predict(img)\n",
        "        ix = 1\n",
        "        n_img = self.img.shape[0]\n",
        "        n_fm = len(feature_maps)+1\n",
        "        #print(n_img,n_fm)\n",
        "        for ix2 in range(n_img):\n",
        "                plt.subplot(n_img,n_fm,ix2*n_fm+1).imshow(mask[ix2,:,:,0],cmap = 'gray')\n",
        "                for ix1 in range(n_fm-1):\n",
        "                    ix = ix2*(n_fm)+(ix1+2)\n",
        "                    #print(ix)\n",
        "                    plt.subplot(n_img,n_fm, ix ).imshow(feature_maps[ix1][ix2,:,:,0],cmap = 'gray')\n",
        "    \n",
        "        plt.show()\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0QEKvbCdEox"
      },
      "source": [
        "#efficient Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUse0GipHrr"
      },
      "source": [
        "def efficient_unet(image_shape,num_class,weights=None):\n",
        "  data = Input(shape=image_shape)\n",
        "  mvn0 = Lambda(mvn)(data)\n",
        "  conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "  conv1 = Lambda(mvn)(conv1)\n",
        "  conv1 = Activation('relu')(conv1)\n",
        "  conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "  conv1 = Lambda(mvn)(conv1)\n",
        "  conv1 = Activation('relu')(conv1)\n",
        "  base =  app.efficientnet.EfficientNetB4(include_top=False, weights=None, input_tensor= conv1)\n",
        "  x=base.get_layer(\"top_activation\").output #7x7x1280 chia 32\n",
        "  skip1=base.get_layer(\"block6a_expand_activation\").output \n",
        "  skip2 =base.get_layer(\"block4a_expand_activation\").output \n",
        "  skip3 = base.get_layer(\"block3a_expand_activation\").output \n",
        "  skip4 = base.get_layer(\"block2a_expand_activation\").output \n",
        "  skip5 = base.layers[9].output \n",
        "  model = decode_unet(x,data,skip1,skip2,skip3,skip4,skip5)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAg3HIMGiHfw"
      },
      "source": [
        "def xcep_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.Xception(include_top=False, weights=None, input_tensor= conv1)\n",
        "    x=base.get_layer(\"block14_sepconv2_act\").output #chia 32\n",
        "    skip1=base.get_layer(\"block13_sepconv2_bn\").output #chia 16\n",
        "    skip2 =base.get_layer(\"block4_sepconv2_bn\").output  #chia 8\n",
        "    skip3 = base.get_layer(\"block3_sepconv2_bn\").output \n",
        "    skip3 = ZeroPadding2D(((0,1),(0,1)))(skip3)\n",
        "    skip4 = base.get_layer(\"block2_sepconv2_bn\").output\n",
        "    skip4 = ZeroPadding2D(((1,2),(1,2)))(skip4)\n",
        "    skip5 =conv1\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0DUMW6vXAk"
      },
      "source": [
        "def block_inception_a(input):\n",
        "    inter_channel = input.get_shape().as_list()[3]\n",
        "    branch_0 = conv2d_bn(input, inter_channel//4, 1, 1)\n",
        "\n",
        "    branch_1 = conv2d_bn(input, inter_channel//5, 1, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, inter_channel//4, 3, 3)\n",
        "\n",
        "    branch_2 = conv2d_bn(input, inter_channel//5, 1, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, inter_channel//4, 3, 3)\n",
        "\n",
        "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "    branch_3 = conv2d_bn(branch_3, inter_channel//4, 1, 1)\n",
        "\n",
        "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=-1)\n",
        "    return x\n",
        "def incep_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.InceptionV3(include_top=False, weights=None, input_tensor= data)\n",
        "    x=base.layers[-3].output #chia 32\n",
        "    x = ZeroPadding2D(((0,1),(0,1)))(x)\n",
        "    skip1=base.layers[228].output #chia 16\n",
        "    skip2 =base.layers[86].output  #chia 8\n",
        "    skip2 = Cropping2D(((0,1),(0,1)))(skip2)\n",
        "    skip3 = base.layers[16].output \n",
        "    skip3 = Cropping2D(((2,2),(2,2)))(skip3)\n",
        "    #skip3 = ZeroPadding2D(((0,1),(0,1)))(skip3)\n",
        "    skip4 = base.layers[9].output\n",
        "    #skip4 = ZeroPadding2D(((1,2),(1,2)))(skip4)\n",
        "    skip5 = base.layers[1].output\n",
        "    print(\"output: \",x.shape)\n",
        "    print(\"skip1 shape: \",skip1.shape)\n",
        "    print(\"skip2 shape: \",skip2.shape)\n",
        "    print(\"skip3 shape: \",skip3.shape)\n",
        "    print(\"skip4 shape: \",skip4.shape)\n",
        "    print(\"skip5 shape: \",skip5.shape)\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5 = None)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ShTOBpC5ec"
      },
      "source": [
        "def mobile_unet(image_shape,num_class,weights=None):\n",
        "    data = Input(shape=image_shape)\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    base =  app.MobileNet(include_top=False, weights=None, input_tensor= conv1)\n",
        "    x=base.layers[-7].output #chia 32\n",
        "    #x = ZeroPadding2D(((0,1),(0,1)))(x)\n",
        "    skip1=base.layers[73+7].output #chia 16\n",
        "    skip2 =base.layers[36+7].output  #chia 8\n",
        "    skip3 = base.layers[23+7].output #chia4\n",
        "    skip4 = base.layers[10+7].output  #chia2\n",
        "    skip5 = conv1\n",
        "    print(\"output: \",x.shape)\n",
        "    print(\"skip1 shape: \",skip1.shape)\n",
        "    print(\"skip2 shape: \",skip2.shape)\n",
        "    print(\"skip3 shape: \",skip3.shape)\n",
        "    print(\"skip4 shape: \",skip4.shape)\n",
        "    print(\"skip5 shape: \",skip5.shape)\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNZwcBr3IP-m"
      },
      "source": [
        "def vgg_unet(image_shape,num_class,weights=None):\n",
        "    base =  app.VGG16(include_top=False, weights='imagenet', input_shape = (image_shape))\n",
        "    #skip1 = base.get_layer('block5_conv3') #chia 16\n",
        "    skip1 = base.get_layer('block4_conv3').output #chia 8\n",
        "    skip2 = base.get_layer('block3_conv3').output #chia 4\n",
        "    skip3 = base.get_layer('block2_conv2').output #chia 2\n",
        "    skip4 = base.get_layer('block1_conv2').output #chia 1\n",
        "    x = base.layers[-2].output\n",
        "    data = base.layers[0].output\n",
        "    model = decode_unet(x, data, skip1,skip2,skip3,skip4,skip5 = None)\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz7l78gsbCCw"
      },
      "source": [
        "def unet(input_size = (192,288,3),classnum=2,pretrained_weights = None):\n",
        "    data = Input(shape=input_size, dtype='float', name='data')\n",
        "    mvn0 = Lambda(mvn)(data)\n",
        "    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = block_inception_a(conv1)\n",
        "    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n",
        "    conv1 = Lambda(mvn)(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n",
        "    conv2 = Lambda(mvn)(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    conv2 = block_inception_a(conv2)\n",
        "    conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n",
        "    conv2 = Lambda(mvn)(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n",
        "    conv3 = Lambda(mvn)(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = block_inception_a(conv3)\n",
        "    conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n",
        "    conv3 = Lambda(mvn)(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n",
        "    conv4 = Lambda(mvn)(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    conv4 = block_inception_a(conv4)\n",
        "    conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n",
        "    conv4 = Lambda(mvn)(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n",
        "    conv5 = Lambda(mvn)(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    conv5 = block_inception_a(conv5)\n",
        "    conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n",
        "    conv5 = Lambda(mvn)(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    #pool5 = MaxPooling2D(pool_size=(2, 2))(drop5)\n",
        "\n",
        "    # convx = Conv2D(1024, 3,  padding = 'same')(pool5)\n",
        "    # convx = Lambda(mvn)(convx)\n",
        "    # convx = Activation('relu')(convx)\n",
        "    # convx = Conv2D(1024, 3,  padding = 'same')(convx)\n",
        "    # convx = Lambda(mvn)(convx)\n",
        "    # convx = Activation('relu')(convx)\n",
        "    # dropx = Dropout(0.5)(convx)\n",
        "\n",
        "\n",
        "    model = decode_unet(drop5,data,conv4,conv3,conv2,conv1,skip5 = None)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veBOYeZyrhBS"
      },
      "source": [
        "def decode_unet(x,data,skip1,skip2,skip3,skip4,skip5):\n",
        "\n",
        "    # neu co skip 5 thi skip 1 la feature map chia 16, skip2 chia 8, skip3 chia 4, skip4 chia 2, skip5 chia 1\n",
        "    # neu khong co skip5 thi skip 1 la chia 8 va lan luot\n",
        "    # x la feature map output cua encoder\n",
        "    # data la input cua network\n",
        "\n",
        "    if skip5 is not None:\n",
        "        #filters = [1024,728,256,128,64]\n",
        "        filters = [1024,512,256,128,64]\n",
        "    else:\n",
        "        filters = [512,256,128,64]\n",
        "\n",
        "    merge6 = attention_up_and_concate(x,skip1)\n",
        "    conv6 = Conv2D(filters[0], 3,  padding = 'same')(merge6)\n",
        "    conv6 = Lambda(mvn)(conv6)\n",
        "    conv6 = Activation('relu')(conv6)\n",
        "    conv6 = Conv2D(filters[0], 3,  padding = 'same')(conv6)\n",
        "    conv6 = Lambda(mvn)(conv6)\n",
        "    conv6 = Activation('relu')(conv6)\n",
        "\n",
        "\n",
        "    \n",
        "    merge7 = attention_up_and_concate(conv6,skip2)\n",
        "    conv7 = Conv2D(filters[1], 3,  padding = 'same')(merge7)\n",
        "    conv7 = Lambda(mvn)(conv7)\n",
        "    conv7 = Activation('relu')(conv7)\n",
        "    conv7 = Conv2D(filters[1], 3,  padding = 'same')(conv7)\n",
        "    conv7 = Lambda(mvn)(conv7)\n",
        "    conv7 = Activation('relu')(conv7)\n",
        "\n",
        "    \n",
        "    merge8 = attention_up_and_concate(conv7,skip3)\n",
        "    conv8 = Conv2D(filters[2], 3,  padding = 'same')(merge8)\n",
        "    conv8 = Lambda(mvn)(conv8)\n",
        "    conv8 = Activation('relu')(conv8)\n",
        "    conv8 = Conv2D(filters[2], 3,  padding = 'same')(conv8)\n",
        "    conv8 = Lambda(mvn)(conv8)\n",
        "    conv8 = Activation('relu')(conv8)\n",
        "\n",
        "\n",
        "     \n",
        "    merge9 = attention_up_and_concate(conv8,skip4)\n",
        "    conv9 = Conv2D(filters[3], 3,  padding = 'same')(merge9)\n",
        "    conv9 = Lambda(mvn)(conv9)\n",
        "    conv9 = Activation('relu')(conv9)\n",
        "    conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "    \n",
        "    if skip5 is not None:\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        merge10 = attention_up_and_concate(conv9,skip5)\n",
        "        conv10 = Conv2D(filters[4], 3,  padding = 'same')(merge10)\n",
        "        conv10 = Lambda(mvn)(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(filters[4], 3,  padding = 'same')(conv10)\n",
        "        #conv10 = Activation('relu')(conv10)\n",
        "        edge_out = Conv2D(1, 1,name = \"output1\")(conv10)\n",
        "        conv10 = Lambda(mvn)(conv10)\n",
        "        #conv10 = BatchNormalization()(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(2, 3,  padding = 'same')(conv10)\n",
        "        conv10 = Activation('relu')(conv10)\n",
        "        conv10 = Conv2D(1, 1,name = \"main_output\")(conv10)\n",
        "        #out = tf.keras.layers.Activation(\"sigmoid\",name = \"main_output\")(conv10)\n",
        "        model = Model(inputs = data, outputs = [conv10,edge_out])\n",
        "    else:\n",
        "        #conv9 = Lambda(mvn)(conv9)\n",
        "        #conv9 = Activation('relu')(conv9)\n",
        "        #conv9 = UpSampling2D()(conv9)\n",
        "        #conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv9 = Conv2D(filters[3], 3,  padding = 'same')(conv9)\n",
        "        edge_out = Conv2D(1, 1,name = \"output1\")(conv9)\n",
        "        conv9 = Lambda(mvn)(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv9 = Conv2D(2, 3,  padding = 'same')(conv9)\n",
        "        conv9 = Activation('relu')(conv9)\n",
        "        conv10 = Conv2D(1, 1,padding = 'same')(conv9)\n",
        "        #print(\"output shape:\",conv10.shape)\n",
        "        conv10 = tf.keras.layers.Activation(\"sigmoid\",name = \"main_output\")(conv10)\n",
        "        model = Model(inputs = data, outputs = [conv10,conv8,skip4])\n",
        "    return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4efkGcj6nHv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " #from itertools import izip\n",
        "generator_x = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect',\n",
        "    #brightness_range = (0.9,1.1),\n",
        ")\n",
        "generator_y = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    #width_shift_range = 0.2,\n",
        "    #height_shift_range = 0.2,\n",
        "    #shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    #brightness_range = (1.0,1.0),\n",
        "    rotation_range = 180,\n",
        "    #fill_mode = 'reflect'\n",
        ")\n",
        "seed = 1234\n",
        "batch = 4\n",
        "#X_train, X_test, y_train, y_test = train_test_split(imgs, masks, test_size=0.1)\n",
        "x_gen = generator_x.flow(imgs, batch_size = batch, shuffle = False, seed = seed)\n",
        "y_gen = generator_y.flow(masks, batch_size = batch, shuffle = False, seed = seed)\n",
        "train_generator = zip(x_gen, y_gen)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d707bUi8U-y6"
      },
      "source": [
        "# Fit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4OOhfQjWHlO"
      },
      "source": [
        "Epoch 60/80\n",
        "500/500 [==============================] - 288s 576ms/step - loss: 0.3507 - acc: 0.9603 - dice_coef: 0.9069 - jaccard_coef: 0.8409 - val_loss: 0.4036 - val_acc: 0.9290 - val_dice_coef: 0.8515 - val_jaccard_coef: 0.7673"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5EfZgNlGmQN"
      },
      "source": [
        "input_shape = (h, w, 3)\n",
        "img = imgs[5:7]\n",
        "mask = masks[5:7]\n",
        "plt.subplot(121),plt.imshow(img[0,:,:,0].astype(\"uint8\"),cmap='gray')\n",
        "plt.subplot(122),plt.imshow(mask[0,:,:,0].astype(\"uint8\"),cmap='gray')\n",
        "plt.show()\n",
        "model = vgg_unet(input_shape,2)\n",
        "#model.load_weights(\"/content/weights_save/ACLN.30_0.786.h5\")\n",
        "model.compile(optimizer = SGD(lr = 0.01, momentum = 0.9), loss = {\"main_output\":dice_coef_loss}, \n",
        "              #loss_weights={'main_output': 1., 'output1': 0.2},\n",
        "              metrics = {\"main_output\":[dice_coef]})\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights_save/ACLN.{epoch:02d}_{main_output_val_dice_coef:.3f}.h5', \n",
        "                             monitor='main_output_val_dice_coef',save_best_only=True, verbose=1, save_weights_only=True, mode='max')\n",
        "#lr_decay = lr_scheduler()\n",
        "callback_list = [visualize(img,mask)]\n",
        "history = model.fit(train_generator, steps_per_epoch = imgs.shape[0]//4, epochs = 100, validation_data = (img_dev, mask_dev),callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdbOglNSJE46"
      },
      "source": [
        "img = imgs[6:7]\n",
        "mask = masks[6:7]\n",
        "plt.subplot(121),plt.imshow(img[0,:,:,0].astype(\"uint8\"),cmap='gray')\n",
        "plt.subplot(122),plt.imshow(mask[0,:,:,0].astype(\"uint8\"),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdmlP0Jqah60"
      },
      "source": [
        "print(max(history.history['val_main_output_dice_coef']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OZkHcWPsFr1"
      },
      "source": [
        "Ket qua\n",
        "Dung ham heviside active contour loss tỉ lệ 1 -2 \n",
        "\n",
        "Fine tune từ tập pseudo\n",
        "\n",
        "loss: 0.0579 - accuracy: 0.9366 - dice_coef: 0.8038 - val_loss: 0.0918 - val_accuracy: 0.9235 - val_dice_coef: 0.7649\n",
        "\n",
        "\n",
        "\n",
        "chạy từ đầu ảnh doctor 80 epoch step  = 100/epoch\n",
        "\n",
        "loss: 0.0482 - accuracy: 0.9437 - dice_coef: 0.8340 - val_loss: 0.1061 - val_accuracy: 0.9329 - val_dice_coef: 0.7451\n",
        "\n",
        "\n",
        "chạy từ đầu ảnh pseudo 400step/epoch\n",
        "\n",
        "\n",
        "loss: 0.0359 - accuracy: 0.9481 - dice_coef: 0.8590 - val_loss: 0.1045 - val_accuracy: 0.9298 - val_dice_coef: 0.7416"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eug0by9N6eor"
      },
      "source": [
        "#visualize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQpMuGw-Wca"
      },
      "source": [
        "val_main_output_dice_coefmodel = unet((352,352,3),2,\"/content/drive/My Drive/weight_infection_acl/unet.23_0.72.h5\")\n",
        "mask_pred = model.predict(imgs)\n",
        "mask_copy = mask_pred.copy()\n",
        "mask_pred = heviside(mask_pred,0.01)\n",
        "#mask_pred[mask_pred<0] = 0\n",
        "#mask_pred[mask_pred>0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk1CCkIU_R3o"
      },
      "source": [
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(masks[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FC_3D77Dh0M"
      },
      "source": [
        "epison = 1/3.14159\n",
        "Drc = epison / (3.14159 * (epison * epison + mask_copy[:,:,:,:] * mask_copy[:,:,:,:]))\n",
        "print(K.mean(tf.keras.losses.binary_crossentropy(edge,Drc)))\n",
        "plt.imshow(Drc[1,:,:,0],cmap= 'gray')\n",
        "plt.xticks(np.arange(0, 353, 50))\n",
        "plt.show()   \n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "print(edge[1,:,:,0].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zbV6bj_PaM"
      },
      "source": [
        "x = masks[:,1:,:,:] - masks[:,:-1,:,:] # horizontal and vertical directions \n",
        "y = masks[:,:,1:,:] - masks[:,:,:-1,:]\n",
        "\n",
        "\n",
        "delta_x = x[:,1:,:-2,:]**2\n",
        "delta_y = y[:,:-2,1:,:]**2\n",
        "delta_u = K.sqrt(K.abs(delta_x + delta_y))/np.sqrt(2)\n",
        "print(delta_u.numpy().max())\n",
        "\n",
        "plt.imshow(delta_u[1,:,:,0],cmap= 'gray')\n",
        "plt.show()\n",
        "plt.imshow(edge[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH8fKNgkU-Nw"
      },
      "source": [
        "def dice_coef2(y_true, y_pred, smooth=1.0):\n",
        "    '''Average dice coefficient per batch.'''\n",
        "    axes = (1,2,3)\n",
        "    intersection = K.sum(y_true * y_pred, axis=axes) #AhopM\n",
        "    summation = K.sum(y_true + y_pred, axis=axes)\n",
        "    \n",
        "    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n",
        "\n",
        "def dice_coef_loss2(y_true, y_pred):\n",
        "    return 1-dice_coef2(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVxvlUa5vwdj"
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/weight_infection_acl/unet.55_0.74.h5\")\n",
        "mask_pred = model.predict(img_dev)\n",
        "#mask_pred = heviside(mask_pred,epsilon=0.01)\n",
        "mask_pred[mask_pred<0] = 0\n",
        "mask_pred[mask_pred>0] = 1\n",
        "print(dice_coef2(mask_dev,mask_pred))\n",
        "plt.imshow(mask_pred[1,:,:,0],cmap= 'gray')\n",
        "plt.show()    \n",
        "plt.imshow(mask_dev[1,:,:,0],cmap= 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950EqpOh9Gwn"
      },
      "source": [
        "import tensorflow.keras.applications as app\n",
        "model = app.MobileNet()\n",
        "for count,layer in enumerate(model.layers):\n",
        "\t# check for convolutional layer\n",
        "\t#if 'conv' not in layer.name:\n",
        "\t#\tcontinue\n",
        "\t# get filter weights\n",
        "\tprint(count, layer.name)\n",
        "\t#filters, biases = layer.get_weights()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51Rz4w_C7xB"
      },
      "source": [
        "ixs = [2, 5, 9, 91, 94,97]\n",
        "outputs = [model.layers[i].output for i in ixs]\n",
        "model = Model(inputs=model.inputs, outputs=outputs)\n",
        "pyplot.imshow(imgs[0,:,:,:].astype(\"uint8\"),cmap='gray')\n",
        "pyplot.show()\n",
        "feature_maps = model.predict(imgs[:1,:,:,:])\n",
        "# plot the output from each block\n",
        "square = 2\n",
        "for fmap in feature_maps:\n",
        "    print(fmap.shape)\n",
        "    ix = 1\n",
        "    for _ in range(square):\n",
        "        for _ in range(square):\n",
        "            # specify subplot and turn of axis\n",
        "            ax = pyplot.subplot(square, square, ix)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # plot filter channel in grayscale\n",
        "            if ix > fmap.shape[-1]:\n",
        "                continue\n",
        "            pyplot.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "            ix += 1\n",
        "\t# show the figure\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnKx3sVwjxRL"
      },
      "source": [
        "#plt.figure(1)\n",
        "#plt.subplot(121,aspect='auto')\n",
        "y=history.history['val_dice_coef']\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.title('Model DCS')\n",
        "plt.ylabel('DCS')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#plt.subplot(122,aspect='auto')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}